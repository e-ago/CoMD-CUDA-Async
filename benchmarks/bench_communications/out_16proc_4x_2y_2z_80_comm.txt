+ local A=0
+ local B=0
+ local C=1
+ local D=1
+ local NP=16
+ shift 5
+ local 'PAR=-e -i 4 -j 2 -k 2 -x 80 -y 80 -z 80'
+ date
mer 23 nov 2016, 11.41.15, GMT
+ tee -a run.log
+ echo

+ echo

+ mpirun -x ASYNC_USE_ASYNC=0 -x ASYNC_ENABLE_DEBUG=0 -x COMM_USE_COMM=1 -x COMM_USE_ASYNC=1 -x COMM_USE_GPU_COMM=0 -x MP_ENABLE_DEBUG=0 -x GDS_ENABLE_DEBUG=0 -x ENABLE_DEBUG_MSG=0 -x MLX5_DEBUG_MASK=0 -x MLX5_FREEZE_ON_ERROR_CQE=0 -x MP_DBREC_ON_GPU=0 -x MP_RX_CQ_ON_GPU=0 -x MP_TX_CQ_ON_GPU=0 -x MP_EVENT_ASYNC=0 -x MP_GUARD_PROGRESS=0 -x GDS_DISABLE_WRITE64=0 -x GDS_SIMULATE_WRITE64=0 -x GDS_DISABLE_INLINECOPY=0 -x GDS_ENABLE_WEAK_CONSISTENCY=1 -x GDS_DISABLE_MEMBAR=1 -x CUDA_VISIBLE_DEVICES=0 -x CUDA_DISABLE_UNIFIED_MEMORY=0 --mca btl_openib_want_cuda_gdr 1 --map-by node -np 16 -mca btl_openib_warn_default_gid_prefix 0 /home/hpcagos1/peersync/src/scripts/wrapper.sh /home/hpcagos1/peersync/src/comd-cuda-async/bin/CoMD-cuda-mpi -e -i 4 -j 2 -k 2 -x 80 -y 80 -z 80
# tesla27: picking GPU:0/ CPU: HCA:
# tesla27: picking GPU:0/ CPU: HCA:
# tesla27: picking GPU:0/ CPU: HCA:
# tesla27: picking GPU:0/ CPU: HCA:
# tesla27: picking GPU:0/ CPU: HCA:
# tesla27: picking GPU:0/ CPU: HCA:
# tesla27: picking GPU:0/ CPU: HCA:
# tesla27: picking GPU:0/ CPU: HCA:
# tesla27: picking GPU:0/ CPU: HCA:
# tesla27: picking GPU:0/ CPU: HCA:
# tesla27: picking GPU:0/ CPU: HCA:
# tesla27: picking GPU:0/ CPU: HCA:
# tesla27: picking GPU:0/ CPU: HCA:
# tesla27: picking GPU:0/ CPU: HCA:
# tesla27: picking GPU:0/ CPU: HCA:
[tesla31:18490] mca: base: component_find: unable to open /usr/local/Cluster-Apps/openmpi/gnu/1.10.3/lib/openmpi/mca_mtl_psm: libpsm_infinipath.so.1: cannot open shared object file: No such file or directory (ignored)
[tesla58:02529] mca: base: component_find: unable to open /usr/local/Cluster-Apps/openmpi/gnu/1.10.3/lib/openmpi/mca_mtl_psm: libpsm_infinipath.so.1: cannot open shared object file: No such file or directory (ignored)
[tesla27:11821] mca: base: component_find: unable to open /usr/local/Cluster-Apps/openmpi/gnu/1.10.3/lib/openmpi/mca_mtl_psm: libpsm_infinipath.so.1: cannot open shared object file: No such file or directory (ignored)
[tesla28:23684] mca: base: component_find: unable to open /usr/local/Cluster-Apps/openmpi/gnu/1.10.3/lib/openmpi/mca_mtl_psm: libpsm_infinipath.so.1: cannot open shared object file: No such file or directory (ignored)
[tesla29:14368] mca: base: component_find: unable to open /usr/local/Cluster-Apps/openmpi/gnu/1.10.3/lib/openmpi/mca_mtl_psm: libpsm_infinipath.so.1: cannot open shared object file: No such file or directory (ignored)
[tesla59:01395] mca: base: component_find: unable to open /usr/local/Cluster-Apps/openmpi/gnu/1.10.3/lib/openmpi/mca_mtl_psm: libpsm_infinipath.so.1: cannot open shared object file: No such file or directory (ignored)
[tesla94:05343] mca: base: component_find: unable to open /usr/local/Cluster-Apps/openmpi/gnu/1.10.3/lib/openmpi/mca_mtl_psm: libpsm_infinipath.so.1: cannot open shared object file: No such file or directory (ignored)
[tesla92:18252] mca: base: component_find: unable to open /usr/local/Cluster-Apps/openmpi/gnu/1.10.3/lib/openmpi/mca_mtl_psm: libpsm_infinipath.so.1: cannot open shared object file: No such file or directory (ignored)
[tesla97:43875] mca: base: component_find: unable to open /usr/local/Cluster-Apps/openmpi/gnu/1.10.3/lib/openmpi/mca_mtl_psm: libpsm_infinipath.so.1: cannot open shared object file: No such file or directory (ignored)
[tesla57:04022] mca: base: component_find: unable to open /usr/local/Cluster-Apps/openmpi/gnu/1.10.3/lib/openmpi/mca_mtl_psm: libpsm_infinipath.so.1: cannot open shared object file: No such file or directory (ignored)
[tesla95:43039] mca: base: component_find: unable to open /usr/local/Cluster-Apps/openmpi/gnu/1.10.3/lib/openmpi/mca_mtl_psm: libpsm_infinipath.so.1: cannot open shared object file: No such file or directory (ignored)
[tesla98:35445] mca: base: component_find: unable to open /usr/local/Cluster-Apps/openmpi/gnu/1.10.3/lib/openmpi/mca_mtl_psm: libpsm_infinipath.so.1: cannot open shared object file: No such file or directory (ignored)
[tesla96:02015] mca: base: component_find: unable to open /usr/local/Cluster-Apps/openmpi/gnu/1.10.3/lib/openmpi/mca_mtl_psm: libpsm_infinipath.so.1: cannot open shared object file: No such file or directory (ignored)
[tesla93:11686] mca: base: component_find: unable to open /usr/local/Cluster-Apps/openmpi/gnu/1.10.3/lib/openmpi/mca_mtl_psm: libpsm_infinipath.so.1: cannot open shared object file: No such file or directory (ignored)
[tesla99:11266] mca: base: component_find: unable to open /usr/local/Cluster-Apps/openmpi/gnu/1.10.3/lib/openmpi/mca_mtl_psm: libpsm_infinipath.so.1: cannot open shared object file: No such file or directory (ignored)
# tesla27: picking GPU:0/ CPU: HCA:
[tesla30:22926] mca: base: component_find: unable to open /usr/local/Cluster-Apps/openmpi/gnu/1.10.3/lib/openmpi/mca_mtl_psm: libpsm_infinipath.so.1: cannot open shared object file: No such file or directory (ignored)
Wed Nov 23 11:41:17 2016: Starting Initialization


Mini-Application Name    : CoMD-cuda-mpi
Mini-Application Version : 1.1
Platform:
  hostname: tesla27
  kernel name: 'Linux'
  kernel release: '3.10.0-327.36.3.el7.x86_64'
  processor: 'x86_64'
Build:
  CC: '/usr/local/Cluster-Apps/openmpi/gnu/1.10.3/bin/mpicc'
  compiler version: 'gcc (GCC) 5.3.0'
  CFLAGS: '-std=c++11 -Wno-unused-result -DMAXATOMS=64  -DNDEBUG  -DCOMD_DOUBLE -DDO_MPI -DUSE_ASYNC -I/home/hpcagos1/peersync/include  -I/usr/local/Cluster-Apps/openmpi/gnu/1.10.3/include/openmpi/opal/mca/hwloc/hwloc191/hwloc/include -I/usr/local/Cluster-Apps/openmpi/gnu/1.10.3/include/openmpi/opal/mca/event/libevent2021/libevent -I/usr/local/Cluster-Apps/openmpi/gnu/1.10.3/include/openmpi/opal/mca/event/libevent2021/libevent/include -I/usr/local/Cluster-Apps/openmpi/gnu/1.10.3/include -I/usr/local/Cluster-Apps/openmpi/gnu/1.10.3/include/openmpi -I/home/hpcagos1/peersync/include -I/usr/local/Cluster-Apps/cuda/8.0/include -D_NVPROF_NVTX -DUSE_ASYNC'
  LDFLAGS: ' -L/home/hpcagos1/peersync/lib -lmp -lgdsync -lgdrapi -lcuda -libverbs  -lnvToolsExt -lm -lstdc++ -L/usr/local/Cluster-Apps/cuda/8.0/lib64 -lcudart '
  using MPI: true
  Threading: none
  Double Precision: true
Run Date/Time: 2016-11-23, 11:41:17

Command Line Parameters:
  doeam: 1
  potDir: pots
  potName: Cu_u6.eam
  potType: funcfl
  nx: 80
  ny: 80
  nz: 80
  xproc: 4
  yproc: 2
  zproc: 2
  Lattice constant: -1 Angstroms
  nSteps: 100
  printRate: 10
  Time step: 1 fs
  Initial Temperature: 600 K
  Initial Delta: 0 Angstroms

  GPU async opt: 0
  GPU profiling mode: 0
  GPU method: thread_atom
  Space-filling (Hilbert): 0

Host tesla27 using GPU 0: Tesla K20c

RANK[0]: useNL:0,  sim->method:0
Host tesla29 using GPU 0: Tesla K20c

RANK[2]: useNL:0,  sim->method:0
Host tesla58 using GPU 0: Tesla K20c

RANK[6]: useNL:0,  sim->method:0
Host tesla59 using GPU 0: Tesla K20c

RANK[7]: useNL:0,  sim->method:0
Host tesla57 using GPU 0: Tesla K20c

RANK[5]: useNL:0,  sim->method:0
Host tesla28 using GPU 0: Tesla K20c

RANK[1]: useNL:0,  sim->method:0
Host tesla31 using GPU 0: Tesla K20c

RANK[4]: useNL:0,  sim->method:0
Host tesla30 using GPU 0: Tesla K20c

RANK[3]: useNL:0,  sim->method:0
Host tesla95 using GPU 0: Tesla K20c

RANK[11]: useNL:0,  sim->method:0
Host tesla97 using GPU 0: Tesla K20c

RANK[13]: useNL:0,  sim->method:0
Host tesla98 using GPU 0: Tesla K20c

RANK[14]: useNL:0,  sim->method:0
Host tesla96 using GPU 0: Tesla K20c

RANK[12]: useNL:0,  sim->method:0
Host tesla93 using GPU 0: Tesla K20c

RANK[9]: useNL:0,  sim->method:0
Host tesla92 using GPU 0: Tesla K20c

RANK[8]: useNL:0,  sim->method:0
Host tesla99 using GPU 0: Tesla K20c

RANK[15]: useNL:0,  sim->method:0
Host tesla94 using GPU 0: Tesla K20c

RANK[10]: useNL:0,  sim->method:0
[11821] GDS INFO  gds_enable_write64() GDS_DISABLE_WRITE64=0
[11821] GDS INFO  gds_enable_inlcpy() GDS_DISABLE_INLINECOPY=0
[11821] GDS INFO  gds_simulate_write64() GDS_SIMULATE_WRITE64=0
[11821] GDS INFO  gds_enable_membar() GDS_DISABLE_MEMBAR=1
[2015] GDS INFO  gds_enable_write64() GDS_DISABLE_WRITE64=0
[4022] GDS INFO  gds_enable_write64() GDS_DISABLE_WRITE64=0
[35445] GDS INFO  gds_enable_write64() GDS_DISABLE_WRITE64=0
[43039] GDS INFO  gds_enable_write64() GDS_DISABLE_WRITE64=0
[18490] GDS INFO  gds_enable_write64() GDS_DISABLE_WRITE64=0
[1395] GDS INFO  gds_enable_write64() GDS_DISABLE_WRITE64=0
[5343] GDS INFO  gds_enable_write64() GDS_DISABLE_WRITE64=0
[14368] GDS INFO  gds_enable_write64() GDS_DISABLE_WRITE64=0
[11686] GDS INFO  gds_enable_write64() GDS_DISABLE_WRITE64=0
[11266] GDS INFO  gds_enable_write64() GDS_DISABLE_WRITE64=0
[2529] GDS INFO  gds_enable_write64() GDS_DISABLE_WRITE64=0
[43875] GDS INFO  gds_enable_write64() GDS_DISABLE_WRITE64=0
[23684] GDS INFO  gds_enable_write64() GDS_DISABLE_WRITE64=0
[18252] GDS INFO  gds_enable_write64() GDS_DISABLE_WRITE64=0
[22926] GDS INFO  gds_enable_write64() GDS_DISABLE_WRITE64=0
[43039] GDS INFO  gds_enable_inlcpy() GDS_DISABLE_INLINECOPY=0
[18490] GDS INFO  gds_enable_inlcpy() GDS_DISABLE_INLINECOPY=0
[1395] GDS INFO  gds_enable_inlcpy() GDS_DISABLE_INLINECOPY=0
[5343] GDS INFO  gds_enable_inlcpy() GDS_DISABLE_INLINECOPY=0
[14368] GDS INFO  gds_enable_inlcpy() GDS_DISABLE_INLINECOPY=0
[11686] GDS INFO  gds_enable_inlcpy() GDS_DISABLE_INLINECOPY=0
[11266] GDS INFO  gds_enable_inlcpy() GDS_DISABLE_INLINECOPY=0
[2529] GDS INFO  gds_enable_inlcpy() GDS_DISABLE_INLINECOPY=0
[43875] GDS INFO  gds_enable_inlcpy() GDS_DISABLE_INLINECOPY=0
[23684] GDS INFO  gds_enable_inlcpy() GDS_DISABLE_INLINECOPY=0
[18252] GDS INFO  gds_enable_inlcpy() GDS_DISABLE_INLINECOPY=0
[22926] GDS INFO  gds_enable_inlcpy() GDS_DISABLE_INLINECOPY=0
[2015] GDS INFO  gds_enable_inlcpy() GDS_DISABLE_INLINECOPY=0
[4022] GDS INFO  gds_enable_inlcpy() GDS_DISABLE_INLINECOPY=0
[35445] GDS INFO  gds_enable_inlcpy() GDS_DISABLE_INLINECOPY=0
[43039] GDS INFO  gds_simulate_write64() GDS_SIMULATE_WRITE64=0
[18490] GDS INFO  gds_simulate_write64() GDS_SIMULATE_WRITE64=0
[1395] GDS INFO  gds_simulate_write64() GDS_SIMULATE_WRITE64=0
[5343] GDS INFO  gds_simulate_write64() GDS_SIMULATE_WRITE64=0
[14368] GDS INFO  gds_simulate_write64() GDS_SIMULATE_WRITE64=0
[11686] GDS INFO  gds_simulate_write64() GDS_SIMULATE_WRITE64=0
[11266] GDS INFO  gds_simulate_write64() GDS_SIMULATE_WRITE64=0
[2529] GDS INFO  gds_simulate_write64() GDS_SIMULATE_WRITE64=0
[43875] GDS INFO  gds_simulate_write64() GDS_SIMULATE_WRITE64=0
[23684] GDS INFO  gds_simulate_write64() GDS_SIMULATE_WRITE64=0
[18252] GDS INFO  gds_simulate_write64() GDS_SIMULATE_WRITE64=0
[22926] GDS INFO  gds_simulate_write64() GDS_SIMULATE_WRITE64=0
[2015] GDS INFO  gds_simulate_write64() GDS_SIMULATE_WRITE64=0
[4022] GDS INFO  gds_simulate_write64() GDS_SIMULATE_WRITE64=0
[35445] GDS INFO  gds_simulate_write64() GDS_SIMULATE_WRITE64=0
[35445] GDS INFO  gds_enable_membar() GDS_DISABLE_MEMBAR=1
[43039] GDS INFO  gds_enable_membar() GDS_DISABLE_MEMBAR=1
[18490] GDS INFO  gds_enable_membar() GDS_DISABLE_MEMBAR=1
[1395] GDS INFO  gds_enable_membar() GDS_DISABLE_MEMBAR=1
[5343] GDS INFO  gds_enable_membar() GDS_DISABLE_MEMBAR=1
[14368] GDS INFO  gds_enable_membar() GDS_DISABLE_MEMBAR=1
[11686] GDS INFO  gds_enable_membar() GDS_DISABLE_MEMBAR=1
[11266] GDS INFO  gds_enable_membar() GDS_DISABLE_MEMBAR=1
[2529] GDS INFO  gds_enable_membar() GDS_DISABLE_MEMBAR=1
[43875] GDS INFO  gds_enable_membar() GDS_DISABLE_MEMBAR=1
[23684] GDS INFO  gds_enable_membar() GDS_DISABLE_MEMBAR=1
[18252] GDS INFO  gds_enable_membar() GDS_DISABLE_MEMBAR=1
[22926] GDS INFO  gds_enable_membar() GDS_DISABLE_MEMBAR=1
[2015] GDS INFO  gds_enable_membar() GDS_DISABLE_MEMBAR=1
[4022] GDS INFO  gds_enable_membar() GDS_DISABLE_MEMBAR=1
[5343] GDS INFO  gds_cq_map_smart() GDS_CQ_MAP_SMART env 0
[2529] GDS INFO  gds_cq_map_smart() GDS_CQ_MAP_SMART env 0
[35445] GDS INFO  gds_cq_map_smart() GDS_CQ_MAP_SMART env 0
[23684] GDS INFO  gds_cq_map_smart() GDS_CQ_MAP_SMART env 0
[11821] GDS INFO  gds_cq_map_smart() GDS_CQ_MAP_SMART env 0
[43039] GDS INFO  gds_cq_map_smart() GDS_CQ_MAP_SMART env 0
[18252] GDS INFO  gds_cq_map_smart() GDS_CQ_MAP_SMART env 0
[2015] GDS INFO  gds_cq_map_smart() GDS_CQ_MAP_SMART env 0
[4022] GDS INFO  gds_cq_map_smart() GDS_CQ_MAP_SMART env 0
[18490] GDS INFO  gds_cq_map_smart() GDS_CQ_MAP_SMART env 0
[1395] GDS INFO  gds_cq_map_smart() GDS_CQ_MAP_SMART env 0
[14368] GDS INFO  gds_cq_map_smart() GDS_CQ_MAP_SMART env 0
[11686] GDS INFO  gds_cq_map_smart() GDS_CQ_MAP_SMART env 0
[43875] GDS INFO  gds_cq_map_smart() GDS_CQ_MAP_SMART env 0
[11266] GDS INFO  gds_cq_map_smart() GDS_CQ_MAP_SMART env 0
[22926] GDS INFO  gds_cq_map_smart() GDS_CQ_MAP_SMART env 0
Simulation data: 
  Total atoms        : 2048000
  Min global bounds  : [   0.0000000000,   0.0000000000,   0.0000000000 ]
  Max global bounds  : [ 289.2000000000, 289.2000000000, 289.2000000000 ]

Decomposition data: 
  Processors         :      4,     2,     2
  Local boxes        :     14,    29,    29 =    11774
  Box size           : [   5.1642857143,   4.9862068966,   4.9862068966 ]
  Box factor         : [   1.0432900433,   1.0073145246,   1.0073145246 ] 
  Max Link Cell Occupancy: 14 of 64

Potential data: 
  Potential type  : EAM
  Species name    : Cu
  Atomic number   : 29
  Mass            : 63.55 amu
  Lattice type    : FCC
  Lattice spacing : 3.615 Angstroms
  Cutoff          : 4.95 Angstroms

Memory data: 
  Intrinsic atom footprint =   88 B/atom 
  Total atom footprint     = 171.875 MB ( 10.74 MB/node)
  Link cell atom footprint =  63.239 MB/node
  Link cell atom footprint =  82.586 MB/node (including halo cell data


Initial energy : -3.460523233086, atom count : 2048000 

Wed Nov 23 11:41:18 2016: Initialization Finished

Wed Nov 23 11:41:18 2016: Starting simulation

#                                                                                         Performance
#  Loop   Time(fs)       Total Energy   Potential Energy     Kinetic Energy  Temperature   (us/atom)     # Atoms
      0       0.00    -3.460523233086    -3.538079224686     0.077555991600     600.0000     0.0000      2048000
     10      10.00    -3.460520824564    -3.529930504820     0.069409680256     536.9773     0.1314      2048000
     20      20.00    -3.460517934268    -3.509741551967     0.049223617700     380.8109     0.1329      2048000
     30      30.00    -3.460516685486    -3.488525249341     0.028008563854     216.6839     0.1347      2048000
     40      40.00    -3.460518311901    -3.477509922683     0.016991610783     131.4530     0.1366      2048000
     50      50.00    -3.460522670642    -3.479755890565     0.019233219923     148.7948     0.1383      2048000
     60      60.00    -3.460526294408    -3.488945235186     0.028418940778     219.8588     0.1398      2048000
     70      70.00    -3.460526986998    -3.496662952439     0.036135965441     279.5603     0.1416      2048000
     80      80.00    -3.460525241704    -3.498977825370     0.038452583666     297.4825     0.1430      2048000
     90      90.00    -3.460522447915    -3.497375106412     0.036852658497     285.1049     0.1449      2048000
    100     100.00    -3.460519900138    -3.495869314361     0.035349414223     273.4753     0.1462      2048000
Wed Nov 23 11:41:20 2016: Ending simulation



Simulation Validation:
  Initial energy  : -3.460523233086
  Final energy    : -3.460519900138
  eFinal/eInitial : 0.999999
  Final atom count : 2048000, no atoms lost


Timings for Rank 0
        Timer        # Calls    Avg/Call (s)   Total (s)    % Loop
___________________________________________________________________
total                      1       2.2396        2.2396      125.87
loop                       1       1.7794        1.7794      100.00
timestep                  10       0.1778        1.7784       99.95
  position               100       0.0000        0.0005        0.03
  velocity               200       0.0000        0.0011        0.06
  redistribute           101       0.0083        0.8336       46.85
    atomHalo             101       0.0017        0.1739        9.78
  force                  101       0.0088        0.8910       50.07
    eamHalo              101       0.0088        0.8890       49.96
commHalo                 202       0.0011        0.2183       12.27
commReduce                39       0.0009        0.0352        1.98

Timing Statistics Across 16 Ranks:
        Timer        Rank: Min(s)       Rank: Max(s)      Avg(s)    Stdev(s)
_____________________________________________________________________________
total                9:    2.2396       0:    2.2396      2.2396      0.0000
loop                 1:    1.7792       6:    1.7796      1.7794      0.0001
timestep             0:    1.7784       8:    1.7786      1.7785      0.0000
  position           6:    0.0005       3:    0.0005      0.0005      0.0000
  velocity          13:    0.0011       2:    0.0013      0.0011      0.0000
  redistribute      11:    0.8310       1:    0.8355      0.8328      0.0012
    atomHalo        11:    0.1713       1:    0.1771      0.1732      0.0014
  force              1:    0.8886      11:    0.8932      0.8914      0.0012
    eamHalo          1:    0.8866      11:    0.8912      0.8893      0.0012
commHalo             5:    0.2176       6:    0.2192      0.2182      0.0005
commReduce           9:    0.0026       2:    0.0358      0.0141      0.0141

---------------------------------------------------
 Average atom update rate:       0.14 us/atom/task
---------------------------------------------------


---------------------------------------------------
 Average all atom update rate:   0.01 us/atom
---------------------------------------------------


---------------------------------------------------
 Average atom rate:            115.15 atoms/us
---------------------------------------------------

Wed Nov 23 11:41:20 2016: CoMD Ending

/home/hpcagos1/peersync/src/comd-cuda-async/bin/CoMD-cuda-mpi -e -i 4 -j 2 -k 2 -x 80 -y 80 -z 80  
/home/hpcagos1/peersync/src/comd-cuda-async/bin/CoMD-cuda-mpi -e -i 4 -j 2 -k 2 -x 80 -y 80 -z 80  
/home/hpcagos1/peersync/src/comd-cuda-async/bin/CoMD-cuda-mpi -e -i 4 -j 2 -k 2 -x 80 -y 80 -z 80  
/home/hpcagos1/peersync/src/comd-cuda-async/bin/CoMD-cuda-mpi -e -i 4 -j 2 -k 2 -x 80 -y 80 -z 80  
/home/hpcagos1/peersync/src/comd-cuda-async/bin/CoMD-cuda-mpi -e -i 4 -j 2 -k 2 -x 80 -y 80 -z 80  
/home/hpcagos1/peersync/src/comd-cuda-async/bin/CoMD-cuda-mpi -e -i 4 -j 2 -k 2 -x 80 -y 80 -z 80  
/home/hpcagos1/peersync/src/comd-cuda-async/bin/CoMD-cuda-mpi -e -i 4 -j 2 -k 2 -x 80 -y 80 -z 80  
/home/hpcagos1/peersync/src/comd-cuda-async/bin/CoMD-cuda-mpi -e -i 4 -j 2 -k 2 -x 80 -y 80 -z 80  
/home/hpcagos1/peersync/src/comd-cuda-async/bin/CoMD-cuda-mpi -e -i 4 -j 2 -k 2 -x 80 -y 80 -z 80  
/home/hpcagos1/peersync/src/comd-cuda-async/bin/CoMD-cuda-mpi -e -i 4 -j 2 -k 2 -x 80 -y 80 -z 80  
/home/hpcagos1/peersync/src/comd-cuda-async/bin/CoMD-cuda-mpi -e -i 4 -j 2 -k 2 -x 80 -y 80 -z 80  
/home/hpcagos1/peersync/src/comd-cuda-async/bin/CoMD-cuda-mpi -e -i 4 -j 2 -k 2 -x 80 -y 80 -z 80  
/home/hpcagos1/peersync/src/comd-cuda-async/bin/CoMD-cuda-mpi -e -i 4 -j 2 -k 2 -x 80 -y 80 -z 80  
/home/hpcagos1/peersync/src/comd-cuda-async/bin/CoMD-cuda-mpi -e -i 4 -j 2 -k 2 -x 80 -y 80 -z 80  
/home/hpcagos1/peersync/src/comd-cuda-async/bin/CoMD-cuda-mpi -e -i 4 -j 2 -k 2 -x 80 -y 80 -z 80  
/home/hpcagos1/peersync/src/comd-cuda-async/bin/CoMD-cuda-mpi -e -i 4 -j 2 -k 2 -x 80 -y 80 -z 80  
+ date
mer 23 nov 2016, 11.41.20, GMT
